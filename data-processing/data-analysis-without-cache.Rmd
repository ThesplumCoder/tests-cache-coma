---
title: "Análisis de Datos de Rendimiento sin Cache"
author: "Anderson Acuña"
date: "2024-12-15"
output: 
  html_document: 
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Extracción de datos

La carga de datos se hace desde el archivo exportado por **DBeaver**, para la 
tabla *events_statements_summary_by_digest* en la base de datos 
*performance_schema*.
```{r}
data_perf_schema <- read.csv(file = "../data/events_statements_summary_by_digest_202412151135.csv")

schema_split <- strsplit(data_perf_schema$SCHEMA_NAME, split = "_")
data_perf_schema$STRUCTURE_BD <- unlist(lapply(schema_split, function(x) { x[1] }))
data_perf_schema <- data_perf_schema[, c("STRUCTURE_BD", setdiff(names(data_perf_schema), "STRUCTURE_BD"))]
data_perf_schema$SCHOOL <- unlist(lapply(schema_split, function(x) { x[2] }))
data_perf_schema <- data_perf_schema[, c("SCHOOL", setdiff(names(data_perf_schema), "SCHOOL"))]
```

Se hace la validación de significancia de los datos recolectados por el 
*performance_schema*. Para este fin se observa cuánto porcentaje corresponde al 
registro especial, caracterizado por `SCHEMA_NAME = NULL` y `DIGEST = NULL`.
```{r}
total_count <- sum(data_perf_schema$COUNT_STAR)
special_row <- subset(data_perf_schema, SCHEMA_NAME == "" & DIGEST == "")
other_statements <- subset(data_perf_schema, DIGEST != "")

row_categories <- matrix(c(special_row$COUNT_STAR, sum(other_statements$COUNT_STAR)) / total_count, 
                         ncol = 2)
colnames(row_categories) <- c("Registro especial", "Otras sentencias")

barplot(row_categories, 
        ylim = c(0, 1), 
        col = c("dodgerblue", "red"), 
        main = "Validación de significancia", 
        ylab = "Porcentaje")
```

Se seleccionan los registros que se relacionan con consultas, es decir, los que 
en la columna `DIGEST_TEXT` contengan la palabra clave `SELECT`.
```{r}
queries_data <- data_perf_schema[grepl("SELECT", data_perf_schema$DIGEST_TEXT), ]
```


# Exploración de datos

Se observa la participación de cada escuela en la muestra.
```{r}
diamond_queries <- queries_data[queries_data$STRUCTURE_BD == "diamante", ]
division_queries <- queries_data[queries_data$STRUCTURE_BD == "division", ]

barplot(sort(table(queries_data$SCHOOL), decreasing = TRUE), 
        las = 2, 
        col = "coral", 
        main = "Consultas a bases de datos", 
        xlab = "Escuela", 
        ylab = "Cantidad")
barplot(sort(table(diamond_queries$SCHOOL), decreasing = TRUE), 
        las = 2, 
        col = "dodgerblue", 
        main = "Consultas a BDs Diamante", 
        xlab = "Escuela", 
        ylab = "Cantidad")
barplot(sort(table(division_queries$SCHOOL), decreasing = TRUE), 
        las = 2, 
        col = "orange", 
        main = "Consultas a BDs División", 
        xlab = "Escuela", 
        ylab = "Cantidad")
```

Sacamos los datos de la base de datos "división" ya que no corresponde a 
interacciones de usuarios sino a procesos internos realizados por la plataforma.
```{r}
queries_data <- subset(queries_data, STRUCTURE_BD != "division")
```

Ordenamos los datos en forma descendente para los valores de **Tiempo de espera 
promedio** (`AVG_TIMER_WAIT`) y **Conteo de veces** (`COUNT_STAR`).
```{r}
ordered_count_star <- queries_data[order(queries_data$COUNT_STAR, 
                                         decreasing = TRUE), ]
ordered_avg_timer_wait <- queries_data[order(queries_data$AVG_TIMER_WAIT, 
                                             decreasing = TRUE), ]
# Remove duplicates.
unique_count_star <- ordered_count_star[!duplicated(ordered_count_star$DIGEST), ]
unique_avg_timer_wait <- ordered_avg_timer_wait[!duplicated(ordered_avg_timer_wait$DIGEST), ]

# TOP
top <- queries_data[intersect(rownames(unique_count_star[1:1000, ]), rownames(unique_avg_timer_wait[1:1000, ])), ]
write.csv(top[1:20, c("DIGEST", "DIGEST_TEXT")], file = "../data/top20-queries.csv")
```

Exploramos cada columna de interés para observar sus parámetros estadísticos.
```{r}
hist(top$AVG_TIMER_WAIT)
boxplot(top$AVG_TIMER_WAIT, 
        outline = FALSE, 
        horizontal = TRUE)

hist(top$COUNT_STAR)
boxplot(top$COUNT_STAR, 
        outline = FALSE, 
        horizontal = TRUE)

hist(top$SUM_ROWS_SENT / top$COUNT_STAR)
boxplot(top$SUM_ROWS_SENT / top$COUNT_STAR, 
        outline = FALSE, 
        horizontal = TRUE)
```

## Análisis individual de las consultas

Importamos las muestras de rendimiento que se produjeron al repetir un ejemplo 
de cada una de las consultas del TOP.
```{r}
query1 <- read.csv(file = "../data/query1.csv")
query2 <- read.csv(file = "../data/query2.csv")
query3 <- read.csv(file = "../data/query3.csv")
query4 <- read.csv(file = "../data/query4.csv")
query5 <- read.csv(file = "../data/query5.csv")
query6 <- read.csv(file = "../data/query6.csv")
query7 <- read.csv(file = "../data/query7.csv")
query8 <- read.csv(file = "../data/query8.csv")
query9 <- read.csv(file = "../data/query9.csv")
query10 <- read.csv(file = "../data/query10.csv")

unit_miliseconds <- 1e-9
unit_seconds <- 1e-12
unit_graphs <- unit_miliseconds
```

Definimos una función que nos permite graficar cada una de las muestras.
```{r}
performance_grapher <- function(query_number, latency, unit_graphs) {
  mean_query <- mean(latency) * unit_graphs
  std_query <- sd(latency) * unit_graphs
  latency <- latency * unit_graphs
  avg_control <- top[query_number, "AVG_TIMER_WAIT"] * unit_graphs
  
  hist(latency, 
       col = adjustcolor("dodgerblue", alpha.f = 0.2),
       main = paste("Rendimiento consulta", query_number), 
       xlab = "Tiempo [ms]", 
       ylab = "Frecuencia")
  abline(v = c(mean_query - std_query, mean_query + std_query), 
         col = "blue", 
         lty = 2, 
         lwd = 1)
  abline(v = mean_query, 
         col = "blue", 
         lwd = 2)
  abline(v = avg_control, 
         col = "coral", 
         lwd = 2)
  
  boxplot(latency, 
          outline = TRUE, 
          horizontal = TRUE, 
          col = adjustcolor("dodgerblue", alpha.f = 0.2), 
          main = paste("Cuartiles de la consulta", query_number), 
          xlab = "Tiempo [ms]")
  summary(latency)
}
```

### Consulta 1
```{r}
performance_grapher(1, query1$TIMER_WAIT, unit_graphs)
```

### Consulta 2
```{r}
performance_grapher(2, query2$TIMER_WAIT, unit_graphs)
```

### Consulta 3
```{r}
performance_grapher(3, query3$TIMER_WAIT, unit_graphs)
```

### Consulta 4
```{r}
performance_grapher(4, query4$TIMER_WAIT, unit_graphs)
```

### Consulta 5
```{r}
performance_grapher(5, query5$TIMER_WAIT, unit_graphs)
```

### Consulta 6
```{r}
performance_grapher(6, query6$TIMER_WAIT, unit_graphs)
```

### Consulta 7
```{r}
performance_grapher(7, query7$TIMER_WAIT, unit_graphs)
```

### Consulta 8
```{r}
performance_grapher(8, query8$TIMER_WAIT, unit_graphs)
```

### Consulta 9
```{r}
performance_grapher(9, query9$TIMER_WAIT, unit_graphs)
```

### Consulta 10
```{r}
performance_grapher(10, query10$TIMER_WAIT, unit_graphs)
```

